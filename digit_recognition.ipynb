{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition\n",
    "\n",
    "Using the digits dataset from sklearn, different classifier models are tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, tree, svm, linear_model, metrics, preprocessing, pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(10,3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' %label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "X = data\n",
    "y = digits.target\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, digits.target, test_size=0.4, random_state=0)\n",
    "\n",
    "# cross validation folds\n",
    "cv = 10\n",
    "\n",
    "\n",
    "# test\n",
    "def test_classifier(predicted, clf):\n",
    "    _, axes = plt.subplots(nrows=1, ncols=7, figsize=(10,3))\n",
    "    for ax, image, prediction in zip(axes, X_test, predicted):\n",
    "        ax.set_axis_off()\n",
    "        image = image.reshape(8,8)\n",
    "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        ax.set_title(f'Prediction: {prediction}')\n",
    "\n",
    "    print(f\"Classifier score: {clf.score(X_test, y_test)}\")\n",
    "\n",
    "    print(f\"Classification report for classifier {clf}:\\n\"\n",
    "          f\"{metrics.classification_report(y_test, predicted)}\\n\")\n",
    "    \n",
    "# cross validation\n",
    "def cross_validate(X, y, clf, cv):\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    print(f\"Cross validation score, using {cv} folds\")\n",
    "    for i, score in enumerate(scores):\n",
    "        print(f\"Test {i}: {score}\")\n",
    "    print(f\"Mean score: {np.mean(scores)}, std: {np.std(scores)}\")\n",
    "    \n",
    "\n",
    "# use grid search to find optimal parameters\n",
    "def fit_grid_search_params(parameters, clf):\n",
    "    clf = GridSearchCV(clf, parameters, cv=cv)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(f\"Optimal setting: {clf.best_params_}\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(\"Results on test set\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal setting: {'n_neighbors': 1}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        60\n",
      "           1       0.97      1.00      0.99        73\n",
      "           2       1.00      1.00      1.00        71\n",
      "           3       0.96      1.00      0.98        70\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.99      0.98      0.98        89\n",
      "           6       0.99      1.00      0.99        76\n",
      "           7       1.00      1.00      1.00        65\n",
      "           8       1.00      0.95      0.97        78\n",
      "           9       0.97      0.96      0.97        74\n",
      "\n",
      "    accuracy                           0.99       719\n",
      "   macro avg       0.99      0.99      0.99       719\n",
      "weighted avg       0.99      0.99      0.99       719\n",
      "\n",
      "Cross validation score, using 10 folds\n",
      "Test 0: 0.9333333333333333\n",
      "Test 1: 1.0\n",
      "Test 2: 0.9722222222222222\n",
      "Test 3: 0.9722222222222222\n",
      "Test 4: 0.9666666666666667\n",
      "Test 5: 0.9833333333333333\n",
      "Test 6: 0.9944444444444445\n",
      "Test 7: 0.9888268156424581\n",
      "Test 8: 0.9832402234636871\n",
      "Test 9: 0.9720670391061452\n",
      "Mean score: 0.9766356300434513, std: 0.01770437808926091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# find optimal K\n",
    "k_values = {'n_neighbors': [1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "knn = fit_grid_search_params(k_values, KNeighborsClassifier())\n",
    "\n",
    "cross_validate(X, y, knn, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal setting: {'max_depth': 15}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93        60\n",
      "           1       0.81      0.84      0.82        73\n",
      "           2       0.93      0.75      0.83        71\n",
      "           3       0.87      0.84      0.86        70\n",
      "           4       0.85      0.84      0.85        63\n",
      "           5       0.85      0.80      0.82        89\n",
      "           6       0.92      0.96      0.94        76\n",
      "           7       0.75      0.94      0.84        65\n",
      "           8       0.75      0.62      0.68        78\n",
      "           9       0.74      0.82      0.78        74\n",
      "\n",
      "    accuracy                           0.83       719\n",
      "   macro avg       0.84      0.84      0.83       719\n",
      "weighted avg       0.84      0.83      0.83       719\n",
      "\n",
      "Cross validation score, using 10 \n",
      "Test 0: 0.7722222222222223\n",
      "Test 1: 0.8444444444444444\n",
      "Test 2: 0.8277777777777777\n",
      "Test 3: 0.7722222222222223\n",
      "Test 4: 0.7777777777777778\n",
      "Test 5: 0.8777777777777778\n",
      "Test 6: 0.8888888888888888\n",
      "Test 7: 0.8435754189944135\n",
      "Test 8: 0.8044692737430168\n",
      "Test 9: 0.8268156424581006\n",
      "Mean score: 0.8235971446306642, std: 0.039754478719760754\n"
     ]
    }
   ],
   "source": [
    "# create decision tree classifier\n",
    "params = {'max_depth': [1,3,5,10,12,15,17,20]}\n",
    "dec_tree = fit_grid_search_params(params, tree.DecisionTreeClassifier())\n",
    "\n",
    "#dec_tree = clf.fit(X_train, y_train)\n",
    "#predicted = dec_tree.predict(X_test)\n",
    "#test_classifier(predicted, dec_tree)\n",
    "\n",
    "cross_validate(X, y, dec_tree, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9819193324061196\n",
      "Cross validation score, using 10 folds\n",
      "Test 0: 0.9444444444444444\n",
      "Test 1: 0.9944444444444445\n",
      "Test 2: 0.9777777777777777\n",
      "Test 3: 0.9111111111111111\n",
      "Test 4: 0.9777777777777777\n",
      "Test 5: 0.9888888888888889\n",
      "Test 6: 0.9777777777777777\n",
      "Test 7: 0.9441340782122905\n",
      "Test 8: 0.9608938547486033\n",
      "Test 9: 0.9553072625698324\n",
      "Mean score: 0.9632557417752947, std: 0.02402037522167597\n",
      "Using dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'svc', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'svc__C', 'svc__break_ties', 'svc__cache_size', 'svc__class_weight', 'svc__coef0', 'svc__decision_function_shape', 'svc__degree', 'svc__gamma', 'svc__kernel', 'svc__max_iter', 'svc__probability', 'svc__random_state', 'svc__shrinking', 'svc__tol', 'svc__verbose'])\n",
      "\n",
      "\n",
      "Optimal setting: {'svc__C': 2.5, 'svc__degree': 2, 'svc__kernel': 'poly'}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        60\n",
      "           1       0.99      0.99      0.99        73\n",
      "           2       0.99      0.99      0.99        71\n",
      "           3       0.96      0.97      0.96        70\n",
      "           4       1.00      0.98      0.99        63\n",
      "           5       0.98      0.96      0.97        89\n",
      "           6       0.99      0.99      0.99        76\n",
      "           7       0.98      0.98      0.98        65\n",
      "           8       0.96      0.99      0.97        78\n",
      "           9       0.97      0.97      0.97        74\n",
      "\n",
      "    accuracy                           0.98       719\n",
      "   macro avg       0.98      0.98      0.98       719\n",
      "weighted avg       0.98      0.98      0.98       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create support vector machine classifier\n",
    "\n",
    "clf = pipeline.make_pipeline(preprocessing.StandardScaler(), svm.SVC())\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Score: {clf.score(X_test, y_test)}\")\n",
    "cross_validate(X, y, clf, cv)\n",
    "\n",
    "print(f\"Using {clf.get_params().keys()}\")\n",
    "print()\n",
    "\n",
    "param_grid = [\n",
    "    {'svc__C': np.linspace(1, 3, 5), 'svc__gamma': np.linspace(0, 1, 4), 'svc__kernel': ['rbf']},\n",
    "    {'svc__C': np.linspace(1, 3, 5), 'svc__degree': [2, 3, 4, 5], 'svc__kernel': ['poly']},\n",
    "]\n",
    "\n",
    "print()\n",
    "svc = fit_grid_search_params(param_grid, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier score: 0.9248956884561892\n",
      "Classification report for classifier RidgeClassifier():\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        60\n",
      "           1       0.92      0.89      0.90        73\n",
      "           2       0.87      0.96      0.91        71\n",
      "           3       0.94      0.91      0.93        70\n",
      "           4       0.97      0.95      0.96        63\n",
      "           5       0.94      0.96      0.95        89\n",
      "           6       0.95      0.95      0.95        76\n",
      "           7       0.94      0.97      0.95        65\n",
      "           8       0.97      0.78      0.87        78\n",
      "           9       0.82      0.91      0.86        74\n",
      "\n",
      "    accuracy                           0.92       719\n",
      "   macro avg       0.93      0.93      0.93       719\n",
      "weighted avg       0.93      0.92      0.92       719\n",
      "\n",
      "\n",
      "Optimal setting: {'alpha': 3.0}\n",
      "\n",
      "Results on test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        60\n",
      "           1       0.92      0.89      0.90        73\n",
      "           2       0.87      0.96      0.91        71\n",
      "           3       0.94      0.91      0.93        70\n",
      "           4       0.97      0.95      0.96        63\n",
      "           5       0.96      0.96      0.96        89\n",
      "           6       0.95      0.95      0.95        76\n",
      "           7       0.94      0.97      0.95        65\n",
      "           8       0.97      0.78      0.87        78\n",
      "           9       0.82      0.91      0.86        74\n",
      "\n",
      "    accuracy                           0.92       719\n",
      "   macro avg       0.93      0.93      0.93       719\n",
      "weighted avg       0.93      0.92      0.92       719\n",
      "\n",
      "Cross validation score, using 10 folds\n",
      "Test 0: 0.9222222222222223\n",
      "Test 1: 0.9388888888888889\n",
      "Test 2: 0.9111111111111111\n",
      "Test 3: 0.8388888888888889\n",
      "Test 4: 0.9111111111111111\n",
      "Test 5: 0.8944444444444445\n",
      "Test 6: 0.9555555555555556\n",
      "Test 7: 0.9497206703910615\n",
      "Test 8: 0.8491620111731844\n",
      "Test 9: 0.888268156424581\n",
      "Mean score: 0.9059373060211051, std: 0.037345286944261875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create ridge classifier\n",
    "rc = linear_model.RidgeClassifier()\n",
    "rc = rc.fit(X_train, y_train)\n",
    "predicted = rc.predict(X_test)\n",
    "test_classifier(predicted, rc)\n",
    "\n",
    "# use grid search to tune alpha\n",
    "params = {'alpha': np.linspace(1, 4, 10)}\n",
    "rc = fit_grid_search_params(params, linear_model.RidgeClassifier())\n",
    "\n",
    "cross_validate(X, y, rc, cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
